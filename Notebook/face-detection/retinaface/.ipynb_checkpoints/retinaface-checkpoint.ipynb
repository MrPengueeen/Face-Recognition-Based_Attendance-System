{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d615562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "resp = RetinaFace.detect_faces(\"./Test-Images/2.jpg\")\n",
    "img = cv2.imread(\"./Test-Images/1.jpg\")\n",
    "for key in resp.keys():\n",
    "    face = resp[key]\n",
    "    xmin = face['facial_area'][0]\n",
    "    ymin = face['facial_area'][1]\n",
    "    xmax = face['facial_area'][2]\n",
    "    ymax = face['facial_area'][3]\n",
    "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color=(255,0,0), thickness=2)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "cv2.namedWindow(\"Detected Faces\", cv2.WINDOW_NORMAL) \n",
    "  \n",
    "cv2.resizeWindow(\"Detected Faces\", 1000, 700) \n",
    "\n",
    "cv2.imshow(\"Detected Faces\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "faces = DeepFace.extract_faces(img_path = \"./Test-Images/5.jpg\", \n",
    "        target_size = (200, 200), \n",
    "        detector_backend = 'fastmtcnn'\n",
    ")\n",
    "# print(faces[0])\n",
    "for face in faces:\n",
    "    plt.imshow(face['face'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a557cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Temporary Database for the classroom\n",
    "\n",
    "from deepface import DeepFace\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "onlyfiles = [f for f in listdir('./Verification-Images') if isfile(join('./Verification-Images', f))]\n",
    "\n",
    "database = []\n",
    "\n",
    "start = time.time()\n",
    "for file in onlyfiles:\n",
    "    name = file.rstrip('.jpg')\n",
    "    embedding = DeepFace.represent('./Verification-Images/{file}'.format(file=file), model_name = 'Facenet', align=True, detector_backend='retinaface', enforce_detection = False)\n",
    "    temp = {\n",
    "        'name': name,\n",
    "        'face_embedding': embedding,\n",
    "    }\n",
    "    database.append(temp)\n",
    "end = time.time()\n",
    "database_creation_time = end - start\n",
    "print('Time taken for creating face embedding database: {time} seconds'.format(time=database_creation_time))\n",
    "print('Number of student information in the database: {number}'.format(number=len(database)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262021b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from deepface.modules import verification as vr\n",
    "\n",
    "start_total = time.time()\n",
    "threshold = vr.find_threshold('Facenet', 'euclidean')\n",
    "faces = RetinaFace.extract_faces(img_path = \"./Test-Images/20.jpg\", align = True)\n",
    "present_students = []\n",
    "\n",
    "for face in faces:\n",
    "    img = Image.fromarray(face)\n",
    "    img.save('temp.jpg')\n",
    "    \n",
    "    start = time.time()\n",
    "    embedding = np.array(DeepFace.represent('./temp.jpg', model_name = 'Facenet', align=True, detector_backend='retinaface', enforce_detection = False))\n",
    "    for student in database:\n",
    "        source = student['face_embedding'][0]['embedding']\n",
    "        target = embedding[0]['embedding']\n",
    "        distance = vr.find_euclidean_distance(source, target)\n",
    "        if distance <= threshold:\n",
    "            end = time.time()\n",
    "            present_students.append(student)\n",
    "            plt.imshow(face)\n",
    "            plt.show()\n",
    "            print('Recognised Student: {recognised_student}'.format(recognised_student = student['name']))\n",
    "            print('Euclidean distance: {dst}'.format(dst=distance))\n",
    "            print('Time taken in embedding and recognition: {time}'.format(time = end-start))\n",
    "            break\n",
    "    \n",
    "\n",
    "end_total = time.time()\n",
    "print(\"Total time: {time}\".format(time=end_total-start_total))\n",
    "print('Number of detected faces: {detected_faces}'.format(detected_faces=len(faces)))\n",
    "print('Number of recognized students: {recognized_num}'.format(recognized_num=len(present_students)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from retinaface import RetinaFace\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from deepface.modules import verification as vr\n",
    "\n",
    "def beginRecognition():\n",
    "    start_total = time.time()\n",
    "    threshold = vr.find_threshold('Facenet', 'euclidean')\n",
    "    faces = RetinaFace.extract_faces(img_path = \"./snapshot.png\", align = True)\n",
    "    present_students = []\n",
    "\n",
    "    for face in faces:\n",
    "        img = Image.fromarray(face)\n",
    "        img.save('temp.jpg')\n",
    "\n",
    "        start = time.time()\n",
    "        embedding = np.array(DeepFace.represent('./temp.jpg', model_name = 'Facenet', align=True, detector_backend='retinaface', enforce_detection = False))\n",
    "        for student in database:\n",
    "            source = student['face_embedding'][0]['embedding']\n",
    "            target = embedding[0]['embedding']\n",
    "            distance = vr.find_euclidean_distance(source, target)\n",
    "            if distance <= threshold:\n",
    "                end = time.time()\n",
    "                present_students.append(student)\n",
    "                plt.imshow(face)\n",
    "                plt.show()\n",
    "                print('Recognised Student: {recognised_student}'.format(recognised_student = student['name']))\n",
    "                print('Euclidean distance: {dst}'.format(dst=distance))\n",
    "                print('Time taken in embedding and recognition: {time}'.format(time = end-start))\n",
    "                break\n",
    "\n",
    "\n",
    "    end_total = time.time()\n",
    "    print(\"Total time: {time}\".format(time=end_total-start_total))\n",
    "    print('Number of detected faces: {detected_faces}'.format(detected_faces=len(faces)))\n",
    "    print('Number of recognized students: {recognized_num}'.format(recognized_num=len(present_students)))\n",
    "\n",
    "\n",
    "url = \"https://192.168.0.100:8080/video\"\n",
    "cap = cv2.VideoCapture(url)\n",
    "captured = False\n",
    "\n",
    "cv2.namedWindow(\"Stream\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Stream', 900, 900) \n",
    "while(True):\n",
    "    camera, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        cv2.imshow(\"Stream\", frame)\n",
    "    q = cv2.waitKey(1)\n",
    "    if q==ord(\"q\"):\n",
    "        break\n",
    "    elif q%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"snapshot.png\"\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        captured = True\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if captured:\n",
    "    beginRecognition()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c3220f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Name:Aonmoy Das\n",
      "Student ID:19702037\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from retinaface import RetinaFace\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from deepface.modules import verification as vr\n",
    "\n",
    "training_data = []\n",
    "\n",
    "name = input(\"Student Name:\")\n",
    "ID = input(\"Student ID:\")\n",
    "\n",
    "url = \"https://192.168.0.102:8080/video\"\n",
    "cap = cv2.VideoCapture(url)\n",
    "captured = False\n",
    "cv2.namedWindow(\"Stream\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Stream', 900, 900) \n",
    "\n",
    "while(True):\n",
    "    camera, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        cv2.imshow(\"Stream\", frame)\n",
    "    q = cv2.waitKey(1)\n",
    "    if q==ord(\"q\"):\n",
    "        break\n",
    "    elif q%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"./session20-21/{filename}.png\".format(filename=ID)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
